Why community-generated tutorials?
==================================

If you're going to learn something, you want to be sure it's right.  Lately there's been a lot of talk (and rightfully so) about problems with the dissemination of scientific knowledge.  Maybe you heard about it yourself in an article like [this one](http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble).  As a scientist myself, I can tell you that these problems are very real, and that they trickle down into the education system.  If you picked up an introductory psychology textbook, I could easily point you to a few sections that are inaccurate, or just plain wrong, because they're based on research that hasn't stood the test of time.  Though textbook authors do their best to correct these problems with the new editions of the books they print, mistakes do slip through the cracks.  And no matter what, they always gloss over details, and are inevitably out of sync with the pulse of current scientific thinking.

So how can we solve this problem?  How can we close the gap between current, bleeding-edge knowledge, and what's being taught?  Ironically, we can use the same "broken" system that scientists use to evaluate their own research : the peer review system.  Peer review in the world of academic publishing isn't broken because it's inherently a bad idea:  it's broken because it's not being implemented correctly.  Here's how it works now - a researcher or group of researchers submits a paper to a journal.  The editor decides whether the paper looks good enough to publish, and if so, three reviewers are assigned to evaluate it.  If most of them like it, then it gets published, usually with some changes they suggest.   Just think about that for a minute: a single person makes the call whether something is going to be considered for publication.  Then, only three people critically evaluate it before it goes out into the world.  Three overworked people who might not even have had the expertise necessary to properly evaluate it!  Most scientists know that this is the wrong way to do things, and people are trying to make a difference through [official](http://www.ncbi.nlm.nih.gov/pubmedcommons/) and [unofficial](http://hadibeenareviewer.wordpress.com/) channels.  The solution is simpler than you'd think - you just need the peer review process to be never-ending, and continue after publication.  Experts should _always_ be able to provide commentary on research, no matter how old it is, and how accepted that research has been into the mainstream.

But what does this have to do with education?  At King Tutorials, we believe that peer review is also essential to the development of effective learning packages.  Why use a static textbook when you can have the community generate and evaluate a set of tutorials?  Using our rating system, package creators are awarded badges based on how effective their tutorials appear to be, and how popular they appear to be among learners.  And of course, package creators will be able to rate the content and quality of other learning packages, as well as make contributions to them.  Three people might mistake fiction for fact, but it's pretty unlikely that one hundred people will! 

To sum it up, by allowing learning packages to be created, evaluated, and modified by the community of teachers and learners, we benefit from all the strengths and none of the weaknesses of the academic publishing system.  What we develop this weekend for Node Knock-Out is not going to be perfect, but we're not going to stop here.  Regardless of what happens after the voting process, we're going to keep going with this project.  The world is full of teachers and learners, and it's about time they get connected.

Dr. Christian Battista
